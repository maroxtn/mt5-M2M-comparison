{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mt5 - test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8OHskLpuz1Z",
        "outputId": "87b8a31e-6ba7-4edc-9905-859f92f4d11a"
      },
      "source": [
        "!pip install simpletransformers -q\n",
        "\n",
        "\n",
        "import logging\n",
        "import pandas as pd\n",
        "from simpletransformers.t5 import T5Model, T5Args"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▌                              | 10kB 24.2MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 30.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 17.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.8MB 24.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5MB 47.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 45.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 57.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 46.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2MB 45.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 60.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 35.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 57.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 35.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 60.9MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datasets 1.8.0 has requirement tqdm<4.50.0,>=4.27, but you'll have tqdm 4.61.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGuk3eIAu2ky"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.enabled = False \n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "set_seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AVOAzJPu73S"
      },
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3lhEQOku9Xt"
      },
      "source": [
        "#For logging loss\n",
        "wandb.login(key=\"INSERT YOUR API KEY\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spWV_4OMvCaL"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "PATH_TO_DATASET = \"../input/yoruba-translation/\"  #Where you stored the dataset\n",
        "\n",
        "train = pd.read_csv(os.path.join(PATH_TO_DATASET, \"Train.csv\"))\n",
        "\n",
        "#Remove any possible duplicates\n",
        "train = train.drop_duplicates(subset=[\"Yoruba\", \"English\"])\n",
        "\n",
        "#Lowercase and remove trailing spaces\n",
        "train[\"Yoruba\"] = train.apply(lambda x: (x.Yoruba).strip().lower(), axis=1)\n",
        "train[\"English\"] = train.English.apply(lambda x: x.lower())\n",
        "\n",
        "train = train[[\"Yoruba\", \"English\"]]\n",
        "train.columns = [\"input_text\", \"target_text\"]\n",
        "\n",
        "#Train 95% / Validation 5% Split\n",
        "validation = train.sample(frac=0.05).astype(str)\n",
        "train = train.drop(index=validation.index).astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OjdsLVSvEQL"
      },
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "train_df = train\n",
        "eval_df = validation\n",
        "\n",
        "train_df[\"prefix\"] = \"\"\n",
        "eval_df[\"prefix\"] = \"\"\n",
        "\n",
        "model_args = T5Args()\n",
        "model_args.max_seq_length = 100\n",
        "model_args.train_batch_size = 10\n",
        "model_args.eval_batch_size = 10\n",
        "model_args.num_train_epochs = 8\n",
        "model_args.scheduler = \"cosine_schedule_with_warmup\"\n",
        "model_args.evaluate_during_training = True\n",
        "model_args.evaluate_during_training_steps = 10000\n",
        "model_args.learning_rate = 0.0003\n",
        "model_args.optimizer = 'Adafactor'\n",
        "model_args.use_multiprocessing = False\n",
        "model_args.fp16 = False\n",
        "model_args.save_steps = -1\n",
        "model_args.save_eval_checkpoints = False\n",
        "model_args.no_cache = True\n",
        "model_args.reprocess_input_data = True\n",
        "model_args.overwrite_output_dir = True\n",
        "model_args.save_model_every_epoch = False\n",
        "model_args.preprocess_inputs = False\n",
        "model_args.use_early_stopping = True\n",
        "model_args.num_return_sequences = 1\n",
        "model_args.do_lower_case = True\n",
        "model_args.output_dir = \"all/\"\n",
        "model_args.best_model_dir = \"all/best_model\"\n",
        "model_args.wandb_project = \"Yoruba fine tune\"\n",
        "\n",
        "model = T5Model(\"mt5\", \"google/mt5-base\", args=model_args)\n",
        "#model.model.load_state_dict(torch.load(\"../input/semifinalyoruba/outputs/best_model/pytorch_model.bin\"))\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df, eval_data=eval_df)\n",
        "\n",
        "# Optional: Evaluate the model. We'll test it properly anyway.\n",
        "results = model.eval_model(eval_df, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8HTrITEvPWX"
      },
      "source": [
        "model_args = T5Args()\n",
        "model_args.max_length = 100\n",
        "model_args.length_penalty = 2.5\n",
        "model_args.repetition_penalty = 1.5\n",
        "model_args.num_beams = 5\n",
        "\n",
        "model = T5Model(\"mt5\", \"all/best_model\", args=model_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkYQdrp1vSzX"
      },
      "source": [
        "preds = model.predict(validation.input_text.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IkHqDMdvUA3"
      },
      "source": [
        "validation[\"preds\"] = preds"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}